\section{Conclusion}
\label{sec:conclusion}

This Master Thesis has attempted to tackle the problem of machine-generated text detection through the lens of a marked attention to model efficiency and size.
The early chapters served to introduce the field and language modelling in general, hopefully helping to initiate those who were so far unfamiliar with the topic.
Chapter \ref{sec:threats} provided an overview of thread models relating to NLG technologies, such as their potential harmful uses in misinformation campaigns, phishing, or false research.
This was meant as justification for the development of detection technologies: it would be wishful thinking to assume that all actors -- regardless of background, competence, or intention -- will disclose their use of language generation, but alerting users that they're dealing with machine text remains critical.
Following up on the outlined threats, Chapter \ref{sec:approaches} outlined some of the most recent detection approaches present in the scientific literature.
These range from statistical strategies relying on classical representations such as word-frequency vectors and TF-IDF, to solutions employing the same large language models in the detection effort.
Aside from the lively research landscape surrounding the field, especially in recent years, another development that was important to highlight was the movement towards increasingly heavy detection systems.
LLMs and other large transformer-based approaches are responsible for the latest state-of-the-art performance, but these architectures also trade often minor gains for compute requirements that relegate the usage of these solutions to dedicated servers, precluding end users from locally executing software they rely on.

The principal objective of this Master Thesis is to contribute to the conversation surrounding detection systems by proposing alternative solutions that approximate SOTA performance while maintaining a lean model constitution.
The battlefield of choice was Task 8 at SemEval-2024 \citep{wang2024semeval}, a shared task built around black-box detection of machine generated text.
Model development targeting the shared task took place in roughly two stages: the first while SemEval-2024 was ongoing, resulting in official submissions to the leaderboards under the banner of team TueCICL, and a later phase in the context of this Thesis.

The models submitted to the task spanned to subtasks, one consisting in binary classification (subtask A) and the other in change point detection (subtask C).
For both subtasks, the approach was to build an ensemble combining representations from a character-level mode, a TF-IDF model, and a third model build on linguistically motivated features.
This effort resulted in middle-of-the pack rankings, as the submitted solutions fell short of the baseline in both instances, and did not show the convincing performance they exhibited in development.

The second phase of development carried on the work on subtask A, a competition track that challenged participants in pure binary classification over human and machine-generated texts.
Having drawn valuable lesson from the experience during the shared task, and with a more firm grounding the latest research, a new batch of models was developed.
The major introduction in the new stage was to split up the general problem of machine-generated text detection into several sub-problems, aiming to determine whether a target text had been generated by some particular model.
Fifteen single-generator classifiers were trained, three for each of the five models that were included in the data provided for the shared task.
Of the three single-generator classifiers targeting each LLM, one was obtained by fine-tuning DistilBERT, and the other by fitting a random forest classifier with either TF-IDF vectors or linguistically motivated feature representations.
These models were then combined into an ensemble model, which processed each target text by computing the probability that it had been generated by each of the single-generator classifiers, then applying a feed-forward network on the obtained 15-feature vector representation.
This ensemble displayed performance above the task-winning model, and even an ensemble variant that did not of the transformer-based components achieved accuracy levels that would nearly have placed it on the podium.
These results strongly support the argument brought forward by this Thesis, i.e. that there exist answers other than huge transformers along the development of high-performing systems.
